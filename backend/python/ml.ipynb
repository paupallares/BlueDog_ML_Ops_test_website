{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary library for MySQL database connection\n",
    "import mysql.connector\n",
    "\n",
    "# establish a connection to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"user_answer\",\n",
    "    port=3307\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "\n",
    "# example query to fetch all records from the \"modelTraining\" table\n",
    "cursor.execute(\"SELECT * FROM modelTraining\")\n",
    "\n",
    "# fetch all the results from the previous query\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# print each record from the results\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the SQL results into a pandas dataframe\n",
    "df = pd.read_sql(\"SELECT * FROM modelTraining\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('modelTraining.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modelTraining.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first: NLP for the \"future goals\" so we can process the words and its meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ssanjua/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/ssanjua/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download necessary resources from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lemmatizer and set of stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # tokenize the text and lemmatize tokens that are not stopwords\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want work outside people\n"
     ]
    }
   ],
   "source": [
    "# test preprocessing, if we did it right, here all the meaningless words like 'to' and 'and' should disappear\n",
    "sample_text = \"I want to work outside and with people\"\n",
    "print(preprocess_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the preprocess_text function to every item in the \"goals\" column\n",
    "goals_processed = [preprocess_text(text) for text in df['goals']]\n",
    "\n",
    "# vectorize the processed goals using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(goals_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the text preprocessing to the \"goals\" column in the dataframe\n",
    "df['goals'] = df['goals'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112 entries, 0 to 111\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   interests           112 non-null    object\n",
      " 1   education           112 non-null    object\n",
      " 2   study_availability  112 non-null    object\n",
      " 3   work_availability   112 non-null    object\n",
      " 4   goals               112 non-null    object\n",
      " 5   recommendation      112 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now we will test the model and adjust the hyperparameters of the decision tree to approach good accuracy. Once the result is satisfactory, we will proceed to create the function for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.29%\n",
      "\n",
      "Classification Report:\n",
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                        Builder Restricted licences       1.00      1.00      1.00         2\n",
      "             Certificate II in Engineering Pathways       1.00      1.00      1.00         3\n",
      "   Certificate III in Engineering Fabrication Trade       1.00      1.00      1.00         1\n",
      "        Certificate IV in Building and Construction       1.00      1.00      1.00         2\n",
      "                       Construction Apprenticeships       1.00      0.50      0.67         4\n",
      "            Home Electrical Installation and Safety       1.00      0.83      0.91         6\n",
      "          Manage finances for new business ventures       0.50      1.00      0.67         3\n",
      "        Plumbing Business Management and Operations       1.00      1.00      1.00         2\n",
      "Prepare to work safely in the construction industry       1.00      1.00      1.00         5\n",
      "\n",
      "                                           accuracy                           0.89        28\n",
      "                                          macro avg       0.94      0.93      0.92        28\n",
      "                                       weighted avg       0.95      0.89      0.90        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variables to numerical format\n",
    "features = df.drop(columns=['recommendation', 'goals'])\n",
    "target = df['recommendation']\n",
    "\n",
    "# convert categorical variables to numerical format\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "X_categorical = encoder.fit_transform(features).toarray()\n",
    "X = hstack([X_categorical, X_tfidf]).toarray()\n",
    "y = target\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# train a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=12)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data):\n",
    "    \n",
    "    # preprocess the 'goals' column from the data using the preprocess_text function\n",
    "    goals_processed = [preprocess_text(text) for text in df['goals']]\n",
    "    # vectorize the processed goals using TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_tfidf = vectorizer.fit_transform(goals_processed)\n",
    "    \n",
    "    # drop the 'recommendation' column to get the feature set\n",
    "    features = df.drop(columns=['recommendation'])\n",
    "    target = df['recommendation']\n",
    "\n",
    "    # convert categorical variables to numerical format using One-Hot Encoding\n",
    "    features_without_goals = features.drop(columns=['goals'])\n",
    "    encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "    X_categorical = encoder.fit_transform(features_without_goals).toarray()\n",
    "\n",
    "    # combine categorical features with the TF-IDF matrix for goals\n",
    "    X = hstack([X_categorical, X_tfidf]).toarray()\n",
    "    y = target\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # train a decision tree classifier\n",
    "    clf = DecisionTreeClassifier(max_depth=15)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return encoder, vectorizer, clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certificate IV in Building and Construction\n"
     ]
    }
   ],
   "source": [
    "def recommend_course(interests, education, study_availability, work_availability, goals, encoder, vectorizer, clf):\n",
    "\n",
    "    # process the goals input using the preprocess_text function\n",
    "    goals_processed = preprocess_text(goals)\n",
    "    \n",
    "    # vectorize the processed goals using the pre-trained TF-IDF vectorizer\n",
    "    goals_vectorized = vectorizer.transform([goals_processed])\n",
    "\n",
    "    # construct a DataFrame for the user's provided data\n",
    "    user_data = pd.DataFrame({\n",
    "        'interests': [interests],\n",
    "        'education': [education],\n",
    "        'study_availability': [study_availability],\n",
    "        'work_availability': [work_availability],\n",
    "        'goals': [goals_processed]\n",
    "    })\n",
    "\n",
    "    # encode user's data to numerical format using the pre-trained encoder\n",
    "    user_encoded = encoder.transform(user_data.drop(columns=['goals'])).toarray()\n",
    "\n",
    "    # combine the encoded categorical features with the TF-IDF vector of goals\n",
    "    user_combined = np.hstack([user_encoded, goals_vectorized.toarray()])\n",
    "\n",
    "    # predict the course recommendation using the trained classifier\n",
    "    recommendation = clf.predict(user_combined)\n",
    "\n",
    "    return recommendation[0]\n",
    "\n",
    "encoder, vectorizer, clf = train_model(df)\n",
    "\n",
    "# To test the recommendation function, lets hardcode some data:\n",
    "course = recommend_course(\"painting\", \"masters\", \"part-time\", \"full-time\", \"become more human\", encoder, vectorizer, clf)\n",
    "print(course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving trained models using joblib\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "encoder, vectorizer, clf = train_model(df)\n",
    "\n",
    "dump(encoder, 'encoder.joblib')\n",
    "dump(vectorizer, 'vectorizer.joblib')\n",
    "dump(clf, 'clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we close the db connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
